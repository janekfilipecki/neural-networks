{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zaawansowane modele językowe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://i.pinimg.com/originals/d6/6a/3e/d66a3e867580854200fa37f08e8addaa.gif \"segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetrenowane modele językowe\n",
    "\n",
    "\n",
    "*   Huggingface: https://huggingface.co/transformers/pretrained_models.html\n",
    "*   Community: https://huggingface.co/models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = tokenizer(\"BERT is designed to pre-train deep bidirectional representations\")\n",
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenized_sentence[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"Śpiulkolot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens([101, 11867, 17922, 13687, 12898, 2102, 102])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dotrenowywanie gotowego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(**tokenizer(\"BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers.\", return_tensors=\"pt\"))\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.last_hidden_state, result.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiment_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"glue\",\"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets[\"train\"][\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\",\"idx\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "small_train_dataset = tokenized_datasets[\"train\"]#.shuffle(seed=42).select(range(10000))\n",
    "small_eval_dataset = tokenized_datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=16)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(sentiment_model.parameters(), lr=5e-5)\n",
    "sentiment_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for batch in tqdm(train_dataloader):\n",
    "\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        batch = {\"attention_mask\": batch['attention_mask'].to(device), \"input_ids\": batch['input_ids'].to(device)}#, \"token_type_ids\":batch['token_type_ids'].to(device)}\n",
    "        outputs = sentiment_model(**batch)\n",
    "        loss = loss_fun(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "#         lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "#         progress_bar.update(1)\n",
    "        losses.append(loss.item())\n",
    "    print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(sentiment_model.state_dict(),\"sentiment_model_dict\")\n",
    "sentiment_model.load_state_dict(torch.load(\"sentiment_model_dict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    labels = batch[\"label\"].to(device)\n",
    "    batch = {\"attention_mask\": batch['attention_mask'].to(device), \"input_ids\": batch['input_ids'].to(device)}#, \"token_type_ids\":batch['token_type_ids'].to(device)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = sentiment_model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=labels)\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odpowiadanie na pytania (Question answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''Warsaw is the capital and largest city of Poland. \n",
    "The metropolis stands on the River Vistula in east-central Poland and its population is officially estimated at 1.8 million \n",
    "residents within a greater metropolitan area of 3.1 million residents, which makes Warsaw the 7th \n",
    "most-populous capital city in the European Union. \n",
    "The city area measures 517 km2 (200 sq mi) and comprises 18 boroughs, \n",
    "while the metropolitan area covers 6,100 km2 (2,355 sq mi).\n",
    "Warsaw is an alpha- global city, a major cultural, political and economic hub, \n",
    "and the country's seat of government. Its historical Old Town was designated a UNESCO World Heritage Site.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'Where does the water in Warsaw come from?',\n",
    "    'context': context}\n",
    "res = nlp(QA_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generacja tekstu:\n",
    "Pograj w grę: https://play.aidungeon.io/main/newGame (model GPT-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obrazki z tekstu\n",
    "https://openai.com/dall-e-2/\n",
    "\n",
    "https://labs.openai.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot\n",
    "https://openai.com/blog/chatgpt/\n",
    "\n",
    "https://chat.openai.com/chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
